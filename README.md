# Green IT - Dynamic Network Topologies
## Overview
The files contained in this repository are designed to test the implementation of a dynamic topology mechanism that performs the following:

* Based on overall network traffic, selects nodes to place into a standby state

* In the standby state, each node maintains one connection to a node in the active state, but shuts down all other connections. The intent is to make no routing decisions and reduce power consumption; all non-local traffic is forwarded from the standby node to the active node

The “Dissertation.pdf” document provides a full explanation of the research, development, and implementation of this project.

## Operation
There are three components in the dynamic topology mechanism:

* A centralized controller

* A collection of network nodes

* The host devices connected to the network nodes

These entities interact in the following loop:

1. Nodes: Send network traffic information to Controller

2. Controller: Analyze network traffic matrix and determine optimal topology

    * Focus on energy consumption reduction through the use of node standby states
    
    * Ensure link utilisation does not rise above a threshold value for any of the links
    
    * Apply optimisation heuristics

3. Controller/Nodes: Send/fetch the topology change information

4. Nodes: Implement the topology change

5. Repeat

For testing purposes, each network node contains a virtual machine that generates traffic to simulate a locally connected network. The full logical topology, including the virtual hosts running on each node and the centralized controller, is shown below:
<div align="center">
    <img src="topology_logical.png" width="600px"</img>
</div>
<br>
The inter-node traffic generated by the hosts is designed to be classified as high, medium, or low load, and the controller correspondingly selects one of the three topologies shown below (grey nodes and links are in the standby state):

* **High traffic load**: No nodes are in the standby state

<div align="center">
    <img src="topology_high.png" width="470px"</img>
</div>
<br>

* **Medium traffic load**: Nodes 1, 2, and 4 are in the standby state

<div align="center">
    <img src="topology_med.png" width="470px"</img>
</div>
<br>

* **Low traffic load**: Nodes 1, 2, 4, 5, and 6 are in the standby state

<div align="center">
    <img src="topology_low.png" width="470px"</img>
</div>
<br>

## Implementation

The full implementation details can be found in Chapter 4 of the “Dissertation.pdf” document.

### Controller

The centralized controller alternates between collecting traffic data from each of the nodes and using the data to determine the optimal topology at that point in time. The controller acts as an sFlow collector, and the sFlow messages sent by each node are used to construct the matrix of inter-node traffic flows. 

#### Main program
1. Define measurement interval and topology configuration filename, and declare variables 
2. Initialise adjacency matrix with full topology
3. Capture measurement start time
4. Enter infinite loop
	1. Clear sFlow data from last captured message 
	2. Get sFlow message from stream input 
	3. Process sFlow message 
		1. Dump unwanted sFlow message fields 
		2. Get the node number of the message agent 
			* Continue to next sFlow message capture if the node number is not one of the expected values. 
		3. Dump unwanted sFlow message fields 
		4. Get the node number of the traffic’s source 
			* Continue to next sFlow message capture if the node number is not one of the expected values. 
		5. Dump unwanted sFlow message fields 
		6. Get the node number of the traffic’s destination 
			* Continue to next sFlow message capture if the node number is not one of the expected values 
		7. Dump unwanted sFlow message fields 
		8. Get the traffic’s packet size 
		9. Dump unwanted sFlow message fields 
	   10. Get the sFlow sampling rate 
	4. If the agent and destination nodes are equal, multiply the packet size by the sample rate and add it to the current traffic count for the corresponding source/destination pair. 
	5. Measure the time difference between now and the measurement start time 
	6. If the time difference is greater than the measurement interval, construct the traffic matrix and optimise the topology 
		1. Capture a new measurement start time 
		2. Use the current and previous traffic counts, the current and previous time differences, and equation 4.1 from the dissertation to calculate the traffic demand for every source/destination node pair 
		3. Store the current traffic count and time difference as the previous traffic count and time difference 
		4. Display the traffic matrix at standard output 
		5. Create a new, empty topology configuration file 
		6. Run the topology optimisation algorithm (shown below) and write the output to the new file 
		7. Compare the new topology with the current topology 
		8. If the files are identical, delete the new file, otherwise, overwrite the old file with the new file 
	7. Return to the start of the loop

#### Optimisation algorithm
1. Store the traffic matrix, adjacency list, output filename, and dynamic topology mechanism deactivation switch state (all passed by value from calling function) 
2. Determine number of nodes in the network, initialise link utilisation threshold, and declare variables
3. Set all nodes to be active
4. Calculate shortest path for each source/destination node pair using Dijkstra’s algorithm
5. Use the traffic matrix and the shortest paths to determine the traffic load on each link
6. Calculate the traffic loading on each node as the sum of the traffic load on all connected links
7. Use the link traffic load and link bandwidths to calculate the link utilisation percentage
8. Find maximum link utilisation percentage
9. If the dynamic topology mechanism is not disabled, loop while the maximum link utilisation is less than the threshold value 
	1. Break the loop if attempts have been made to place each node in standby 
	2. Clear the previously calculated node and link traffic loads 
	3. Set the variable that tracks the reachability of the nodes to false (guarantees at least one execution of the loop below) 
	4. Loop while the link utilisation is above the threshold or one or more nodes are unreachable 
		1. Use the shortest paths to determine the frequency of each node’s use as a transit node 
		2. From the set of nodes that are candidates for standby, find the node that is used as a transit node the least. Use the nodes’ traffic load to resolve any conflicts 
		3. Break the loop if a least used node cannot be determined 
		4. Remove the node from the set of nodes that are candidates for standby 
		5. Store the node’s adjacency information. This is only used if placing the node in standby has to be reversed 
		6. From the set of nodes adjacent to the node to be placed in standby, find the node that is used as a transit node the most. Use the nodes’ traffic load to resolve any conflicts 
		7. Update the adjacency matrix of the node to be placed in standby and all its adjacent nodes 
		8. Recalculate shortest paths for new topology 
		9. Recalculate the traffic load on each link 
		10. Recalculate the link utilisation percentage 
		11. Find maximum link utilisation percentage 
		12. Test if all nodes are reachable from every node 
		13. If the link utilisation is above the threshold or one or more nodes are unreachable, reverse the actions taken to modify the adjacency matrix and return to the start of the loop 
	5. Recalculate the traffic load on each link 
	6. Recalculate the link utilisation percentage 
	7. Find maximum link utilisation percentage 
	8. Return to the start of the loop if the maximum link utilisation is less than the threshold value 
10. Write the next hop in the shortest path for each source/destination node pair to the specified output file
